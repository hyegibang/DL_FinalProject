{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import imageParse as imgP\n",
    "import imageSent as imgS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 255, 255, 3)\n",
      "(56, 255, 255, 3)\n"
     ]
    }
   ],
   "source": [
    "abs_X0, abs_Y0, abs_X1, abs_Y1 = imgP.parseData_Abs()\n",
    "print(abs_X0.shape)\n",
    "print(abs_X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 32, 32, 3)\n",
      "(56, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 15:50:43.310037: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "abs_X0 = imgP.input_prep_fn(abs_X0)\n",
    "abs_X1 = imgP.input_prep_fn(abs_X1)\n",
    "print(abs_X0.shape)\n",
    "print(abs_X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(644, 255, 255, 3)\n",
      "(161, 255, 255, 3)\n"
     ]
    }
   ],
   "source": [
    "art_X0, art_Y0, art_X1, art_Y1 = imgP.parseData_Art()\n",
    "print(art_X0.shape)\n",
    "print(art_X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(644, 32, 32, 3)\n",
      "(161, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "art_X0 = imgP.input_prep_fn(art_X0)\n",
    "art_X1 = imgP.input_prep_fn(art_X1)\n",
    "print(art_X0.shape)\n",
    "print(art_X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAD_map = np.array([\n",
    "    [1,0.735,0.772], #0: 'happy'\n",
    "    [0.918,0.61,0.566], #1: 'funny'\n",
    "    [0.225,0.333,0.149], #2: 'sad'\n",
    "    [0.63,0.52,0.509], #3: 'tender'\n",
    "    [0.95,0.792,0.789], #4: 'exciting'\n",
    "    [0.122,0.83,0.604], #5: 'angry'\n",
    "    [0.062,0.952,0.528], #6: 'scary'\n",
    "])\n",
    "\n",
    "VAD_pd = pd.DataFrame(\n",
    "    columns = [\"valence\", \"arousal\", \"dominance\"], \n",
    "    data = VAD_map, \n",
    "    index = ['happy', 'funny', 'sad', 'tender', \n",
    "             'exciting', 'angry', 'scary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"abs\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             multiple                  224       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           multiple                  1168      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           multiple                  4640      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  multiple                 0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           multiple                  0         \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  491580    \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  183       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 497,799\n",
      "Trainable params: 497,795\n",
      "Non-trainable params: 4\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "abs_model = imgS.ImageSentModel(name='abs')\n",
    "abs_model((abs_X0[:5], abs_Y0[:5]))\n",
    "abs_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "abs_model.compile(optimizer=optimizer, VAD_map=VAD_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_Y0_VAD = VAD_pd.loc[abs_Y0]\n",
    "abs_Y1_VAD = VAD_pd.loc[abs_Y1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "28/28 [==============================] - 1s 30ms/step - mse_loss: 0.6808 - acc: 0.1339\n",
      "Epoch 2/75\n",
      "28/28 [==============================] - 1s 31ms/step - mse_loss: 0.6440 - acc: 0.1339\n",
      "Epoch 3/75\n",
      "28/28 [==============================] - 1s 30ms/step - mse_loss: 0.6460 - acc: 0.1339\n",
      "Epoch 4/75\n",
      "28/28 [==============================] - 1s 28ms/step - mse_loss: 0.6236 - acc: 0.1339\n",
      "Epoch 5/75\n",
      "28/28 [==============================] - 1s 30ms/step - mse_loss: 0.6105 - acc: 0.1339\n",
      "Epoch 6/75\n",
      "28/28 [==============================] - 1s 30ms/step - mse_loss: 0.5913 - acc: 0.1339\n",
      "Epoch 7/75\n",
      "28/28 [==============================] - 1s 29ms/step - mse_loss: 0.5762 - acc: 0.1339\n",
      "Epoch 8/75\n",
      "28/28 [==============================] - 1s 28ms/step - mse_loss: 0.5468 - acc: 0.1339\n",
      "Epoch 9/75\n",
      "28/28 [==============================] - 1s 32ms/step - mse_loss: 0.5362 - acc: 0.1339\n",
      "Epoch 10/75\n",
      "28/28 [==============================] - 1s 28ms/step - mse_loss: 0.4991 - acc: 0.1339\n",
      "Epoch 11/75\n",
      "28/28 [==============================] - 1s 28ms/step - mse_loss: 0.4695 - acc: 0.1339\n",
      "Epoch 12/75\n",
      "28/28 [==============================] - 1s 28ms/step - mse_loss: 0.4438 - acc: 0.1339\n",
      "Epoch 13/75\n",
      "28/28 [==============================] - 1s 28ms/step - mse_loss: 0.4096 - acc: 0.1339\n",
      "Epoch 14/75\n",
      "28/28 [==============================] - 1s 28ms/step - mse_loss: 0.3752 - acc: 0.1295\n",
      "Epoch 15/75\n",
      "28/28 [==============================] - 1s 28ms/step - mse_loss: 0.3516 - acc: 0.1384\n",
      "Epoch 16/75\n",
      "28/28 [==============================] - 1s 31ms/step - mse_loss: 0.3268 - acc: 0.1384\n",
      "Epoch 17/75\n",
      "28/28 [==============================] - 1s 30ms/step - mse_loss: 0.3020 - acc: 0.1429\n",
      "Epoch 18/75\n",
      "28/28 [==============================] - 1s 31ms/step - mse_loss: 0.2842 - acc: 0.1473\n",
      "Epoch 19/75\n",
      "28/28 [==============================] - 1s 29ms/step - mse_loss: 0.2643 - acc: 0.1607\n",
      "Epoch 20/75\n",
      "28/28 [==============================] - 1s 28ms/step - mse_loss: 0.2371 - acc: 0.1429\n",
      "Epoch 21/75\n",
      "28/28 [==============================] - 1s 30ms/step - mse_loss: 0.2191 - acc: 0.1562\n",
      "Epoch 22/75\n",
      "28/28 [==============================] - 1s 29ms/step - mse_loss: 0.2217 - acc: 0.1607\n",
      "Epoch 23/75\n",
      "28/28 [==============================] - 1s 29ms/step - mse_loss: 0.1915 - acc: 0.1652\n",
      "Epoch 24/75\n",
      "28/28 [==============================] - 1s 29ms/step - mse_loss: 0.1734 - acc: 0.1562\n",
      "Epoch 25/75\n",
      "28/28 [==============================] - 1s 30ms/step - mse_loss: 0.1597 - acc: 0.1607\n",
      "Epoch 26/75\n",
      "28/28 [==============================] - 1s 29ms/step - mse_loss: 0.1464 - acc: 0.1518\n",
      "Epoch 27/75\n",
      "28/28 [==============================] - 1s 29ms/step - mse_loss: 0.1301 - acc: 0.1741\n",
      "Epoch 28/75\n",
      "28/28 [==============================] - 1s 28ms/step - mse_loss: 0.1288 - acc: 0.1562\n",
      "Epoch 29/75\n",
      "28/28 [==============================] - 1s 28ms/step - mse_loss: 0.1097 - acc: 0.1786\n",
      "Epoch 30/75\n",
      "28/28 [==============================] - 1s 29ms/step - mse_loss: 0.1060 - acc: 0.1830\n",
      "Epoch 31/75\n",
      "28/28 [==============================] - 1s 28ms/step - mse_loss: 0.1072 - acc: 0.1786\n",
      "Epoch 32/75\n",
      "28/28 [==============================] - 1s 30ms/step - mse_loss: 0.0907 - acc: 0.1830\n",
      "Epoch 33/75\n",
      "28/28 [==============================] - 1s 32ms/step - mse_loss: 0.0838 - acc: 0.1920\n",
      "Epoch 34/75\n",
      "28/28 [==============================] - 1s 32ms/step - mse_loss: 0.0751 - acc: 0.1875\n",
      "Epoch 35/75\n",
      "28/28 [==============================] - 1s 29ms/step - mse_loss: 0.0672 - acc: 0.1786\n",
      "Epoch 36/75\n",
      "28/28 [==============================] - 1s 30ms/step - mse_loss: 0.0660 - acc: 0.1920\n",
      "Epoch 37/75\n",
      "28/28 [==============================] - 1s 29ms/step - mse_loss: 0.0595 - acc: 0.2009\n",
      "Epoch 38/75\n",
      "28/28 [==============================] - 1s 29ms/step - mse_loss: 0.0631 - acc: 0.2143\n",
      "Epoch 39/75\n",
      "28/28 [==============================] - 1s 30ms/step - mse_loss: 0.0543 - acc: 0.2188\n",
      "Epoch 40/75\n",
      "28/28 [==============================] - 1s 28ms/step - mse_loss: 0.0465 - acc: 0.2098\n",
      "Epoch 41/75\n",
      "28/28 [==============================] - 1s 28ms/step - mse_loss: 0.0414 - acc: 0.2188\n",
      "Epoch 42/75\n",
      "28/28 [==============================] - 1s 28ms/step - mse_loss: 0.0470 - acc: 0.2277\n",
      "Epoch 43/75\n",
      "28/28 [==============================] - 1s 29ms/step - mse_loss: 0.0432 - acc: 0.2009\n",
      "Epoch 44/75\n",
      "28/28 [==============================] - 1s 36ms/step - mse_loss: 0.0337 - acc: 0.2232\n",
      "Epoch 45/75\n",
      "28/28 [==============================] - 1s 34ms/step - mse_loss: 0.0317 - acc: 0.2188\n",
      "Epoch 46/75\n",
      "28/28 [==============================] - 1s 36ms/step - mse_loss: 0.0280 - acc: 0.2277\n",
      "Epoch 47/75\n",
      "28/28 [==============================] - 1s 33ms/step - mse_loss: 0.0257 - acc: 0.2366\n",
      "Epoch 48/75\n",
      "28/28 [==============================] - 1s 30ms/step - mse_loss: 0.0257 - acc: 0.2455\n",
      "Epoch 49/75\n",
      "28/28 [==============================] - 1s 32ms/step - mse_loss: 0.0245 - acc: 0.2589\n",
      "Epoch 50/75\n",
      "28/28 [==============================] - 1s 34ms/step - mse_loss: 0.0217 - acc: 0.2500\n",
      "Epoch 51/75\n",
      "28/28 [==============================] - 1s 31ms/step - mse_loss: 0.0192 - acc: 0.2500\n",
      "Epoch 52/75\n",
      "28/28 [==============================] - 1s 30ms/step - mse_loss: 0.0188 - acc: 0.2455\n",
      "Epoch 53/75\n",
      "28/28 [==============================] - 1s 30ms/step - mse_loss: 0.0180 - acc: 0.2545\n",
      "Epoch 54/75\n",
      "28/28 [==============================] - 1s 33ms/step - mse_loss: 0.0157 - acc: 0.2679\n",
      "Epoch 55/75\n",
      "28/28 [==============================] - 1s 31ms/step - mse_loss: 0.0146 - acc: 0.2723\n",
      "Epoch 56/75\n",
      "28/28 [==============================] - 1s 31ms/step - mse_loss: 0.0136 - acc: 0.2723\n",
      "Epoch 57/75\n",
      "28/28 [==============================] - 1s 29ms/step - mse_loss: 0.0131 - acc: 0.2768\n",
      "Epoch 58/75\n",
      "28/28 [==============================] - 1s 29ms/step - mse_loss: 0.0122 - acc: 0.2812\n",
      "Epoch 59/75\n",
      "28/28 [==============================] - 1s 36ms/step - mse_loss: 0.0138 - acc: 0.2723\n",
      "Epoch 60/75\n",
      "28/28 [==============================] - 1s 29ms/step - mse_loss: 0.0116 - acc: 0.2812\n",
      "Epoch 61/75\n",
      "28/28 [==============================] - 1s 34ms/step - mse_loss: 0.0103 - acc: 0.2812\n",
      "Epoch 62/75\n",
      "28/28 [==============================] - 1s 29ms/step - mse_loss: 0.0098 - acc: 0.2991\n",
      "Epoch 63/75\n",
      "28/28 [==============================] - 1s 29ms/step - mse_loss: 0.0089 - acc: 0.2857\n",
      "Epoch 64/75\n",
      "28/28 [==============================] - 1s 28ms/step - mse_loss: 0.0089 - acc: 0.2812\n",
      "Epoch 65/75\n",
      "28/28 [==============================] - 1s 28ms/step - mse_loss: 0.0081 - acc: 0.2812\n",
      "Epoch 66/75\n",
      "28/28 [==============================] - 1s 30ms/step - mse_loss: 0.0074 - acc: 0.2991\n",
      "Epoch 67/75\n",
      "28/28 [==============================] - 1s 28ms/step - mse_loss: 0.0080 - acc: 0.2991\n",
      "Epoch 68/75\n",
      "28/28 [==============================] - 1s 33ms/step - mse_loss: 0.0084 - acc: 0.3036\n",
      "Epoch 69/75\n",
      "28/28 [==============================] - 1s 29ms/step - mse_loss: 0.0075 - acc: 0.2946\n",
      "Epoch 70/75\n",
      "28/28 [==============================] - 1s 29ms/step - mse_loss: 0.0066 - acc: 0.3170\n",
      "Epoch 71/75\n",
      "28/28 [==============================] - 1s 28ms/step - mse_loss: 0.0068 - acc: 0.3080\n",
      "Epoch 72/75\n",
      "28/28 [==============================] - 1s 28ms/step - mse_loss: 0.0068 - acc: 0.3170\n",
      "Epoch 73/75\n",
      "28/28 [==============================] - 1s 29ms/step - mse_loss: 0.0063 - acc: 0.3125\n",
      "Epoch 74/75\n",
      "28/28 [==============================] - 1s 33ms/step - mse_loss: 0.0063 - acc: 0.3125\n",
      "Epoch 75/75\n",
      "28/28 [==============================] - 1s 31ms/step - mse_loss: 0.0057 - acc: 0.3170\n"
     ]
    }
   ],
   "source": [
    "abs_model.fit(\n",
    "    (abs_X0, abs_Y0_VAD), abs_Y0_VAD,\n",
    "    epochs     = 75,\n",
    "    batch_size = 8,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 15ms/step - mse_loss: 1.2404 - acc: 0.1071\n"
     ]
    }
   ],
   "source": [
    "abs_model.evaluate(\n",
    "    (abs_X1, abs_Y1_VAD), abs_Y1_VAD,\n",
    "    batch_size = 8,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"art\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           multiple                  224       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           multiple                  1168      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           multiple                  4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  491580    \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  183       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 497,799\n",
      "Trainable params: 497,795\n",
      "Non-trainable params: 4\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "art_model = imgS.ImageSentModel(name='art')\n",
    "art_model((art_X0[:5], art_Y0[:5]))\n",
    "art_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_model.compile(optimizer=optimizer, VAD_map=VAD_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_Y0_VAD = VAD_pd.loc[art_Y0]\n",
    "art_Y1_VAD = VAD_pd.loc[art_Y1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "81/81 [==============================] - 3s 32ms/step - mse_loss: 0.7536 - acc: 0.1265\n",
      "Epoch 2/75\n",
      "81/81 [==============================] - 3s 36ms/step - mse_loss: 0.7058 - acc: 0.1265\n",
      "Epoch 3/75\n",
      "81/81 [==============================] - 3s 31ms/step - mse_loss: 0.6642 - acc: 0.1296\n",
      "Epoch 4/75\n",
      "81/81 [==============================] - 2s 30ms/step - mse_loss: 0.6157 - acc: 0.1281\n",
      "Epoch 5/75\n",
      "81/81 [==============================] - 3s 33ms/step - mse_loss: 0.5562 - acc: 0.1265\n",
      "Epoch 6/75\n",
      "81/81 [==============================] - 2s 30ms/step - mse_loss: 0.4929 - acc: 0.1281\n",
      "Epoch 7/75\n",
      "81/81 [==============================] - 3s 33ms/step - mse_loss: 0.4465 - acc: 0.1296\n",
      "Epoch 8/75\n",
      "81/81 [==============================] - 3s 32ms/step - mse_loss: 0.3866 - acc: 0.1281\n",
      "Epoch 9/75\n",
      "81/81 [==============================] - 3s 31ms/step - mse_loss: 0.3479 - acc: 0.1296\n",
      "Epoch 10/75\n",
      "81/81 [==============================] - 3s 33ms/step - mse_loss: 0.3053 - acc: 0.1296\n",
      "Epoch 11/75\n",
      "81/81 [==============================] - 3s 32ms/step - mse_loss: 0.2763 - acc: 0.1281\n",
      "Epoch 12/75\n",
      "81/81 [==============================] - 2s 31ms/step - mse_loss: 0.2358 - acc: 0.1327\n",
      "Epoch 13/75\n",
      "81/81 [==============================] - 3s 32ms/step - mse_loss: 0.2121 - acc: 0.1327\n",
      "Epoch 14/75\n",
      "81/81 [==============================] - 3s 32ms/step - mse_loss: 0.1904 - acc: 0.1420\n",
      "Epoch 15/75\n",
      "81/81 [==============================] - 2s 31ms/step - mse_loss: 0.1626 - acc: 0.1358\n",
      "Epoch 16/75\n",
      "81/81 [==============================] - 2s 30ms/step - mse_loss: 0.1485 - acc: 0.1358\n",
      "Epoch 17/75\n",
      "81/81 [==============================] - 2s 30ms/step - mse_loss: 0.1300 - acc: 0.1373\n",
      "Epoch 18/75\n",
      "81/81 [==============================] - 2s 30ms/step - mse_loss: 0.1131 - acc: 0.1373\n",
      "Epoch 19/75\n",
      "81/81 [==============================] - 3s 40ms/step - mse_loss: 0.1059 - acc: 0.1404\n",
      "Epoch 20/75\n",
      "81/81 [==============================] - 3s 39ms/step - mse_loss: 0.0966 - acc: 0.1435\n",
      "Epoch 21/75\n",
      "81/81 [==============================] - 3s 37ms/step - mse_loss: 0.0831 - acc: 0.1497\n",
      "Epoch 22/75\n",
      "81/81 [==============================] - 3s 34ms/step - mse_loss: 0.0790 - acc: 0.1435\n",
      "Epoch 23/75\n",
      "81/81 [==============================] - 3s 38ms/step - mse_loss: 0.0717 - acc: 0.1574\n",
      "Epoch 24/75\n",
      "81/81 [==============================] - 3s 32ms/step - mse_loss: 0.0636 - acc: 0.1559\n",
      "Epoch 25/75\n",
      "81/81 [==============================] - 3s 32ms/step - mse_loss: 0.0564 - acc: 0.1543\n",
      "Epoch 26/75\n",
      "81/81 [==============================] - 3s 33ms/step - mse_loss: 0.0547 - acc: 0.1543\n",
      "Epoch 27/75\n",
      "81/81 [==============================] - 3s 35ms/step - mse_loss: 0.0530 - acc: 0.1605\n",
      "Epoch 28/75\n",
      "81/81 [==============================] - 3s 34ms/step - mse_loss: 0.0467 - acc: 0.1528\n",
      "Epoch 29/75\n",
      "81/81 [==============================] - 3s 35ms/step - mse_loss: 0.0476 - acc: 0.1605\n",
      "Epoch 30/75\n",
      "81/81 [==============================] - 2s 30ms/step - mse_loss: 0.0430 - acc: 0.1590\n",
      "Epoch 31/75\n",
      "81/81 [==============================] - 3s 35ms/step - mse_loss: 0.0412 - acc: 0.1605\n",
      "Epoch 32/75\n",
      "81/81 [==============================] - 3s 32ms/step - mse_loss: 0.0406 - acc: 0.1620\n",
      "Epoch 33/75\n",
      "81/81 [==============================] - 3s 33ms/step - mse_loss: 0.0368 - acc: 0.1620\n",
      "Epoch 34/75\n",
      "81/81 [==============================] - 3s 32ms/step - mse_loss: 0.0337 - acc: 0.1590\n",
      "Epoch 35/75\n",
      "81/81 [==============================] - 3s 34ms/step - mse_loss: 0.0349 - acc: 0.1605\n",
      "Epoch 36/75\n",
      "81/81 [==============================] - 2s 30ms/step - mse_loss: 0.0328 - acc: 0.1590\n",
      "Epoch 37/75\n",
      "81/81 [==============================] - 2s 31ms/step - mse_loss: 0.0335 - acc: 0.1636\n",
      "Epoch 38/75\n",
      "81/81 [==============================] - 2s 30ms/step - mse_loss: 0.0322 - acc: 0.1651\n",
      "Epoch 39/75\n",
      "81/81 [==============================] - 2s 29ms/step - mse_loss: 0.0295 - acc: 0.1790\n",
      "Epoch 40/75\n",
      "81/81 [==============================] - 2s 30ms/step - mse_loss: 0.0309 - acc: 0.1728\n",
      "Epoch 41/75\n",
      "81/81 [==============================] - 3s 33ms/step - mse_loss: 0.0290 - acc: 0.1713\n",
      "Epoch 42/75\n",
      "81/81 [==============================] - 3s 33ms/step - mse_loss: 0.0269 - acc: 0.1744\n",
      "Epoch 43/75\n",
      "81/81 [==============================] - 3s 33ms/step - mse_loss: 0.0294 - acc: 0.1651\n",
      "Epoch 44/75\n",
      "81/81 [==============================] - 3s 39ms/step - mse_loss: 0.0270 - acc: 0.1682\n",
      "Epoch 45/75\n",
      "81/81 [==============================] - 2s 30ms/step - mse_loss: 0.0251 - acc: 0.1728\n",
      "Epoch 46/75\n",
      "81/81 [==============================] - 2s 31ms/step - mse_loss: 0.0282 - acc: 0.1836\n",
      "Epoch 47/75\n",
      "81/81 [==============================] - 3s 35ms/step - mse_loss: 0.0285 - acc: 0.1806\n",
      "Epoch 48/75\n",
      "81/81 [==============================] - 3s 33ms/step - mse_loss: 0.0266 - acc: 0.1713\n",
      "Epoch 49/75\n",
      "81/81 [==============================] - 3s 34ms/step - mse_loss: 0.0256 - acc: 0.1713\n",
      "Epoch 50/75\n",
      "81/81 [==============================] - 3s 32ms/step - mse_loss: 0.0237 - acc: 0.1759\n",
      "Epoch 51/75\n",
      "81/81 [==============================] - 2s 28ms/step - mse_loss: 0.0237 - acc: 0.1790\n",
      "Epoch 52/75\n",
      "81/81 [==============================] - 2s 28ms/step - mse_loss: 0.0282 - acc: 0.1744\n",
      "Epoch 53/75\n",
      "81/81 [==============================] - 2s 29ms/step - mse_loss: 0.0260 - acc: 0.1821\n",
      "Epoch 54/75\n",
      "81/81 [==============================] - 3s 33ms/step - mse_loss: 0.0231 - acc: 0.1790\n",
      "Epoch 55/75\n",
      "81/81 [==============================] - 2s 29ms/step - mse_loss: 0.0233 - acc: 0.1806\n",
      "Epoch 56/75\n",
      "81/81 [==============================] - 2s 29ms/step - mse_loss: 0.0262 - acc: 0.1698\n",
      "Epoch 57/75\n",
      "81/81 [==============================] - 2s 28ms/step - mse_loss: 0.0237 - acc: 0.1790\n",
      "Epoch 58/75\n",
      "81/81 [==============================] - 2s 29ms/step - mse_loss: 0.0234 - acc: 0.1836\n",
      "Epoch 59/75\n",
      "81/81 [==============================] - 2s 30ms/step - mse_loss: 0.0224 - acc: 0.1836\n",
      "Epoch 60/75\n",
      "81/81 [==============================] - 2s 30ms/step - mse_loss: 0.0270 - acc: 0.1836\n",
      "Epoch 61/75\n",
      "81/81 [==============================] - 2s 28ms/step - mse_loss: 0.0286 - acc: 0.1867\n",
      "Epoch 62/75\n",
      "81/81 [==============================] - 2s 29ms/step - mse_loss: 0.0207 - acc: 0.1821\n",
      "Epoch 63/75\n",
      "81/81 [==============================] - 2s 29ms/step - mse_loss: 0.0239 - acc: 0.1867\n",
      "Epoch 64/75\n",
      "81/81 [==============================] - 2s 29ms/step - mse_loss: 0.0236 - acc: 0.1867\n",
      "Epoch 65/75\n",
      "81/81 [==============================] - 2s 28ms/step - mse_loss: 0.0261 - acc: 0.1852\n",
      "Epoch 66/75\n",
      "81/81 [==============================] - 2s 28ms/step - mse_loss: 0.0222 - acc: 0.1836\n",
      "Epoch 67/75\n",
      "81/81 [==============================] - 2s 29ms/step - mse_loss: 0.0224 - acc: 0.1852\n",
      "Epoch 68/75\n",
      "81/81 [==============================] - 2s 29ms/step - mse_loss: 0.0220 - acc: 0.1836\n",
      "Epoch 69/75\n",
      "81/81 [==============================] - 3s 34ms/step - mse_loss: 0.0224 - acc: 0.1821\n",
      "Epoch 70/75\n",
      "81/81 [==============================] - 3s 35ms/step - mse_loss: 0.0218 - acc: 0.1914\n",
      "Epoch 71/75\n",
      "81/81 [==============================] - 3s 39ms/step - mse_loss: 0.0245 - acc: 0.1852\n",
      "Epoch 72/75\n",
      "81/81 [==============================] - 3s 32ms/step - mse_loss: 0.0241 - acc: 0.1944\n",
      "Epoch 73/75\n",
      "81/81 [==============================] - 2s 29ms/step - mse_loss: 0.0254 - acc: 0.1821\n",
      "Epoch 74/75\n",
      "81/81 [==============================] - 2s 30ms/step - mse_loss: 0.0225 - acc: 0.1883\n",
      "Epoch 75/75\n",
      "81/81 [==============================] - 2s 29ms/step - mse_loss: 0.0208 - acc: 0.1991\n"
     ]
    }
   ],
   "source": [
    "art_model.fit(\n",
    "    (art_X0, art_Y0_VAD), art_Y0_VAD,\n",
    "    epochs     = 75,\n",
    "    batch_size = 8,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 15ms/step - mse_loss: 1.0967 - acc: 0.1190\n"
     ]
    }
   ],
   "source": [
    "art_model.evaluate(\n",
    "    (art_X1, art_Y1_VAD), art_Y1_VAD,\n",
    "    batch_size = 8,\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (dl3)",
   "language": "python",
   "name": "dl3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
